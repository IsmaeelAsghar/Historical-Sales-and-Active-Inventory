"# Historical-Sales" 
"# Historical-Sales" 
"# Historical-Sales" 
"# Historical-Sales-and-Active-Inventory" 


Why Use XGBoost and Random Forest?
Handle Nonlinear Relationships: Both models can capture complex, nonlinear interactions among features, unlike logistic regression.
Feature Importance: Both models provide insights into variable importance.
High Performance: XGBoost delivers state-of-the-art accuracy in many classification tasks.
Imbalance Handling: XGBoost offers built-in support for class weighting and evaluation metrics tailored for imbalanced data.
Robustness: Random Forest reduces overfitting by averaging multiple decision trees.


Why Not Use Other Models:
Logistic Regression: Limited to linear relationships; fails to capture complex patterns.

Decision Trees: Prone to overfitting, especially with small or imbalanced datasets.

Other Linear Models (e.g., SVM Linear, Linear Discriminant Analysis): Poor performance on nonlinear and high-dimensional data without kernel tricks or preprocessing.
